''' First autoencoder had layers of sizes 384, 16, 384.
	Second autoencoder was 16, 8, 16.
	These two were sigmoid layers.

	Another neural network of layers 8, 4 was takes for the output layer(softmax layer).

	This is currently configured for 2nd auto encoder.
	The values are replaced as specified in the below comments to train the other autoencoders as well.
'''


import neurolab as nl
import numpy

XTr= []
YTr= []	#Needed Only For Last Network

def calcH(x):
	'''Caculates the hidden layer values'''
	"""Return the output of the network if ``a`` is input."""
	x=[x]
	x=numpy.array(x)
	x=numpy.transpose(x)
	h=numpy.add(numpy.transpose(numpy.array(numpy.dot(net.layers[0].np["w"],x))),numpy.array(net.layers[0].np["b"]))
	h=sigmoid_vec(numpy.transpose(h))
	return h

def sigmoid(z):
	return 2.0/(1.0+numpy.exp(-2*z))-1

sigmoid_vec = numpy.vectorize(sigmoid)

def train():
	global net

	'''Has to be XTr, YTr for the last file and read YTr values from the file YTr.txt'''

	err = net.train(XTr, YTr, epochs= 20, show=1)

def getWeights(nm):
	fp2=open(nm,"w")
	for i in net.layers[0].np['w']:
		fp2.write(",".join([str(j) for j in i]))
		fp2.write("\n")

def getInputs(nm):

	'''This function is not needed for the last layer'''

	global XTr
	fp2=open(nm,"w")
	for i in XTr:
		fp2.write(",".join([str(k) for j in calcH(i) for k in j]))
		fp2.write("\n")

''' 
	384 inputs for first layer, 16 inputs for second layer(as here) and 8 inputs for the last layer
'''

inp= [[0.0, 1.0]]* 8

''' This is for the second autoencoder'''
''' For the first autoencoder, 

	net= nl.net.newff(inp, [16, 384],transf= [nl.trans.TanSig(), nl.trans.SoftMax()])

	For the last layer,

	net= nl.net.newff(inp, [4],transf= [nl.trans.SoftMax()])

'''

net= nl.net.newff(inp, [4],transf= [nl.trans.SoftMax()])



fp= open("H4.txt", "r") # This input file same as the getInputs file of the previous autoencoder(if any)
for line in fp:
	line= line.strip().split(",")
	line= [float(j) for j in line]
	XTr.append(line)

fp= open("YTr.txt", "r") # Use only in case of last network, for outputs
for line in fp:
	line= line.strip().split(",")
	line= [float(j) for j in line]
	YTr.append(line)

train()

''' These weights generated by every autoencoder is used as fixed weights for a separate neural network 
	of the same structure.
'''

getWeights("W5.txt")  #Change to different file for every network

# getInputs("H4.txt") #Only needed for last softmax layer